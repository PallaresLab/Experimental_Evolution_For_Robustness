---
title: "Nex_Go_morphometrics"
output: html_document
date: "2023-12-30"
---

```{r setup libraries, include=FALSE}
#install.packages("onewaytests")
#install.packages("pheatmap")

library(stringr)
library(readr)
library(geomorph)
library(gplots)
library(ggplot2)
library(ggpubr)
library(borealis)
library(readr)
library(ggstatsplot)
library(onewaytests)
library(pheatmap)
library(Evomorph)
library(tidyverse)
library(dplyr)
library(reshape)
library(csaw)
library(RColorBrewer)
```

```{r 1 -> Prepare input for MorphoJ check, echo=FALSE}
#Go load 12 necessary folders with csv files
G0R1 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R2 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R3 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R4 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R5 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R6 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R7 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R8 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R9 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R10 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R12 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
G0R12 <- read_csv("~/Desktop/morphometrics/microscopy_data/annotated_files/")
 ...
 
# assign each file its condition prior to merging them in one.
G0R1$condition = "ctrl_fs"
G0R2$condition = "ctrl_fs"
G0R3$condition = "ctrl_fs"
G0R4$condition = "ctrl_ns"
G0R5$condition = "ctrl_ns"
G0R6$condition = "ctrl_ns"
G0R7$condition = "hgSg_fs"
G0R8$condition = "hgSg_fs"
G0R9$condition = "hgSg_fs"
G0R10$condition = "hgSg_ns"
G0R11$condition = "hgSg_ns"
G0R12$condition = "hgSg_ns"
#merge all 12
complete = rbind(G0R1,G0R2,G0R3,G0R4,G0R5,G0R6,G0R7,G0R8,G0R9,G0R10,G0R11,G0R12)
complete$symetry = ifelse(str_detect(complete$id, "R"), print("R"), print("L"))
complete$id = paste(complete$id, complete$condition, complete$symetry, sep = "_")
write.table(complete, "NEX_morphometrics_Go.txt", quote = F)
#The output must be first checked with morphoJ for swaped landmarks.
#Outlier images can also be removed later in Geomorph.
```

```{r 2 -> Read output of MorphoJ and annotate it for geomorph, echo=FALSE}
NEX_wings = read_csv("~/NEX_morphoJ_final_output.txt")

fw.links <- matrix(c(1,7, 7,12, 12,13, 13,14, 14,15, 4,5, 8,9, 10,11, 8,9, 15,11, 5,11, 3,5, 3,9, 
                     6,8, 2,7, 6,12, 8,13, 10,14, 9,10, 12,7, 2,6 ),
                   ncol = 2, byrow = TRUE)

#data prep
NEX_wings$symetry = ifelse(str_detect(NEX_wings$id, "R"), print("R"), print("L"))
NEX_wings$ind = str_split_i(NEX_wings$id, "_",3)
NEX_wings$diet = str_split_i(NEX_wings$id, "_",1)
NEX_wings$condition = paste(NEX_wings$diet ,str_split_i(NEX_wings$id, "_",2), sep = "_")
NEX_wings$pair = stringr::str_extract(NEX_wings$ind, "^.{3}")
#NEX_wings$pair = paste(NEX_wings$condition, NEX_wings$pair, sep = "_")
length(unique(NEX_wings$pair))
dim(NEX_wings)
cord <- as.matrix(NEX_wings[,2:31])
shape <- arrayspecs(cord, 15, 2)
#shape_fix = estimate.missing(shape) 
```

```{r 3 -> Geomorph analysis: PCA, echo=FALSE}
myGPA<-gpagen(shape) #first we perform gpa, then we rotate.
shapes_aligned <- align.reflect(myGPA, top.pt = 7, links = fw.links,provenance = NULL )
myGPA <- align.procrustes(shapes_aligned, outlier.analysis = TRUE) # helps to remove outliers

#clearly assign metadata
myGPA$condition = NEX_wings$condition
myGPA$ids = NEX_wings$id
myGPA$symetry = NEX_wings$symetry
myGPA$pairs = NEX_wings$pair
NEX_wings$condition=ifelse(NEX_wings$condition == "ctrl_ns", paste("Control diet"), NEX_wings$condition )
NEX_wings$condition=ifelse(NEX_wings$condition == "ctrl_fs", paste("Control diet"), NEX_wings$condition )
NEX_wings$condition=ifelse(NEX_wings$condition == "hgSg_ns", paste("High Sugar diet"), NEX_wings$condition )
NEX_wings$condition=ifelse(NEX_wings$condition == "hgSg_fs", paste("High Sugar diet"), NEX_wings$condition )
#perform generic PCA
wing.pca <- gm.prcomp(shapes_aligned$coords)
wing.pca$condition = NEX_wings$condition
plot(wing.pca, col = as.factor(NEX_wings$condition))
ggGMMplot(wing.pca, group = NEX_wings$condition, group.title = 'Condition', convex.hulls = TRUE,include.legend = TRUE, label.groups = F)
m = mshape(shapes_aligned$coords)
shape.space(wing.pca, group = NEX_wings$condition, group.title = 'Condition', convex.hulls = T,
            backtransform.examples = TRUE,ref.shape = m, shape.method = "points",
            bt.shape.mag = 4,bt.links = fw.links,pt.size = 1, label.groups = F)

```

```{r 4 -> Symetry analysis, echo=FALSE}
bs = bilat.symmetry(shapes_aligned$coords, ind = shapes_aligned$pairs, side =  shapes_aligned$symetry) #check if object.sym=T is required, my understanding is that its only necessery for radially symetrical images, or if two wings were present in the same file.

#4.1 - extract and plot sizes
sizes_per_group = as.data.frame(myGPA$Csize, myGPA$Cond_full)
sizes_per_group$Cond_full  = rownames(sizes_per_group)
sizes_per_group$size = sizes_per_group$`myGPA$Csize`
ggplot(sizes_per_group, aes(x=sizes_per_group$`myGPA$Csize`, fill = Cond_full)) + geom_density(alpha = 0.6, position = "identity", bins = 30) + theme_minimal() + xlab("Wing size distribution per group")
sizes_per_group$logsize=  log10(sizes_per_group$size)
ggbetweenstats(
  data  = sizes_per_group,
  x     = Cond_full,
  y     = logsize,
  title = "Wing size distribution per group", pairwise.display = "significant", centrality.plotting = F, p.adjust.method = "bonferroni",xlab = "Groups",results.subtitle = FALSE, ylab = "Log 10 -Wing Centrod Size", palette = "Accent")

#4.2 - extract and plot asymetry index
symetry_per_group = as.data.frame(bs$signed.AI, bs$condition)
symetry_per_group$CONDITION  = rownames(symetry_per_group)
symetry_per_group$CONDITION = stringr::str_extract(symetry_per_group$CONDITION, "^.{10}")
symetry_per_group = na.omit(symetry_per_group) # character 'ind' by default is added to condition (Geomorph shows that twis is combined data)
symetry_per_group$CONDITION =  ifelse(symetry_per_group$CONDITION == "indctrl_ns", paste("Control diet + no selection"), symetry_per_group$CONDITION )
symetry_per_group$CONDITION =  ifelse(symetry_per_group$CONDITION == "indctrl_fs", paste("Control diet + flight selection"), symetry_per_group$CONDITION )
symetry_per_group$CONDITION =  ifelse(symetry_per_group$CONDITION == "indhgSg_ns", paste("High Sugar diet + no selection"), symetry_per_group$CONDITION )
symetry_per_group$CONDITION =  ifelse(symetry_per_group$CONDITION == "indhgSg_fs", paste("High Sugar diet + flight selection"), symetry_per_group$CONDITION )
symetry_per_group$AI = symetry_per_group$`bs$signed.AI`
ggplot(symetry_per_group, aes(x=symetry_per_group$`bs$signed.AI`, fill = CONDITION)) + geom_histogram(alpha = 0.7, position = "identity", bins = 30) + theme_minimal()
ggbetweenstats(
  data  = symetry_per_group,
  x     = CONDITION,
  y     = AI,
  title = "Wing symetry index distribution per group", centrality.plotting = F, p.adjust.method = "bonferroni",xlab = "Groups", ylab = "Symetry Index",results.subtitle = FALSE, palette = "Accent")
# Geomorph produces AI in two forms: signed and unsigned.
#Signed represents 


#4.3 - seperate FA and DA in four groups (two groups in Go)
#Geomorph calculates FA/DA for the whole object, thus myGPA needs to be subset in two objects based on condition and symetry checked again.
#Symetry output for DA/FA is reported along with significance values ONLY when me - measurement error has been calculated.
#A subset of 100 wings is used for me, repeated measurements are imported seperately, removed from analysis prior to integration with flight data to avoid duplicate values.

repeatability_me_estimate <-read.csv("~/Desktop/GitHub/2023_Experimental_Evolution_For_Robustness/code/") ##add the csv file name

coords.control <- shapes_aligned$coords[ , , shapes_aligned$condition == "Control food"]
Csize.control <- shapes_aligned$size[shapes_aligned$condition == "Control food" ]
ids <- shapes_aligned$species[shapes_aligned$id == "Control food"]
gpa_control <- geomorph.data.frame(coords = coords.control, Csize = Csize.control, ids = ids)

coords.hs <- shapes_aligned$coords[ , , shapes_aligned$condition != "Control food"]
Csize.hs <- shapes_aligned$size[shapes_aligned$condition != "Control food" ]
ids <- shapes_aligned$species[shapes_aligned$id != "Control food"]
gpa_hs <- geomorph.data.frame(coords = coords.hs, Csize = Csize.hs, ids = ids)

bs_control = bilat.symmetry(coords.control$coords, ind = coords.control$pairs, side =  coords.control$symetry)
bs_hs = bilat.symmetry(coords.hs$coords, ind = coords.hs$pairs, side =  coords.hs$symetry) 
#two functions above automatically produce plots, save with concrete names to avoid confusion
```

```{r 5 -> Regressions: average differences between groups, echo=FALSE}
#We can test differences between groups using Procrustes coordinates or PC scores.

#First - using coordinates

#Second - using pcs (not recommended)
pc.scores<-plotTangentSpace(myGPA$coords, warpgrids=F)
myGPA_DF<-geomorph.data.frame(myGPA, pcscores=pc.scores$pc.scores)
w <- lm(myGPA_DF$pcscores[,1]~ log(myGPA_DF$size))
summary(w)
```


```{r 6 -> Flight analysis - changes associated with diet, echo=FALSE}

#
HighSugarFolders = c("phen2705_b2.csv", "" .. )

Go_females_0523_flight_complete <-read.csv("Go_females_0523_flight_complete.csv", row.names = NULL)
Go_females_0523_flight_complete$condition = 
ifelse(Go_females_0523_flight_complete$name_file %in% HighSugarFolders, 
       paste("HighSugar"), paste("ControlDiet"))

# We describe change in flight using four different metrics
# IQR, Mean, CV, and Median
a= ggplot(Go_females_0523_flight_complete, aes(x=name_file, y=Y)) + labs(title = "Mean with bootsrap confidence intervals" ) + theme(axis.text.x = element_text(size = 8))+ xlab("Condition") + ylab("Flight landing")+ stat_summary(fun.data = "mean_cl_boot", colour = "red") 
b= ggplot(Go_females_0523_flight_complete, aes(x=name_file, y=Y)) + labs(title = "Median" ) + theme(axis.text.x = element_text(size = 8))+ xlab("Condition") + ylab("Flight landing")+ stat_summary(fun.y = "median", colour = "red") 
c = ggplot(Go_females_0523_flight_complete, aes(x=name_file, y=Y)) + labs(title = "Median Absolute Deviation" ) + theme(axis.text.x = element_text(size = 8))+ xlab("Condition") + ylab("Flight landing")+ stat_summary(fun.y = "mad", colour = "red") 
d= ggplot(Go_females_0523_flight_complete, aes(x=name_file, y=Y)) + labs(title = "Interquartile range IQR" ) + theme(axis.text.x = element_text(size = 8))+ xlab("Condition") + ylab("Flight landing")+ stat_summary(fun.y = "IQR", colour = "red") 

ggarrange(a, b, c, d, 
          labels = c("A", "B", "C", "D"),
          ncol = 2, nrow = 2)
  
#Next I validate if the change in IQR between two groups is significant.
#We can test these differences using several non-parametric tests.
#Go_females_0523_flight_complete[Go_females_0523_flight_complete$condition == "HighSugar", ]
#Go_females_0523_flight_complete[!Go_females_0523_flight_complete$condition == "HighSugar", ]

#Now we need to assess the variance change. We will use only non-parametric tests to test for significance

#We can first try using the Brown–Forsythe test. This test is similar to Levene test in a sence that it calculates  deviation from the median, except it doesn't require distributions to be parametric. 
bf.test(Y ~ condition, data = Go_females_0523_flight_complete)

#Second we can try using Kruskal–Wallis test. A Kruskal-Wallis Test is used to determine whether or not there is a statistically significant difference between the medians of three or more independent groups. I have just two groups.
kruskal.test(Y ~ condition, data = Go_females_0523_flight_complete) 
```



```{r 7 -> Regressions: flight vs. symetry/size/shape , echo=FALSE}
# 7.1 - To integrate flight analysis with the dataset, we need to import all assigned ID values ordered by Y-axis as well as individual flight values in cm-s. We first merge these two datasets and then overlap that dataframe with the wing coordinates based on the 'ID' colomn

#currently each replica has its own flight csv, ID txt files. Merging them to avoid extra code can be a good idea, otherwise loop-ing the read function.

#I concatenated all flight csv files, preserving rownames and order
Go_females_0523_flight_complete <-read.csv("Go_females_0523_flight_complete.csv", row.names = NULL)
#I also concatinated each order_id into file where each colomn is a 
Go_female_0523_orderID_complete
#wing data can be named as
Go_female_0523_wings_complete


#Maybe it makes sense to make first two in a list rather than a table?
#how to access.

#after files are read, we can combine with this loop
integrate_morphology_and_flight <- function(ids, flight, wings ) {
  row.names(flight) = flight$...1 #flight data always in this shape
  results_with_ids = merge(ids, flight, by = 0) #here we use numbers = the rownames to merge
  results_with_ids$pair = results_with_ids$X1 #clear label to avoid confusion
  results_with_ids$X1 = NULL #removing unecessary coloumn
  #results_with_ids = results_with_ids[,c(1)]
  integrated = merge(results_with_ids, wings, by.y  = "pair",) #here we use ids to merge
  return(integrated)
}

#example below. Make some loop to handle 12 pair of files.
g5r4_integrated = integrate_morphology_and_flight(flight =G5R4_flight, ids = G5R4_values, wings = wings )
#combine all in one
complete_integr = rbind(G0R1_integrated,G0R2_integrated,G0R3_integrated,G0R4_integrated,G0R5_integrated,G0R6_integrated ,G0R7_integrated,G0R8_integrated,G0R9_integrated,G0R10_integrated,G0R11_integrated,G0R12_integrated)
#check if flight correlates with shape of the wing
ggscatter(complete_integr, x = "size", y = "Y", add = "reg.line", conf.int = TRUE,cor.coef = TRUE, cor.method = "pearson")
#subset high-sugar and control data seperately to test if correlation exists.

# 7.2 - Next step in regression analysis is to generate 'average' wings for each ID. For one individual, we need to have a flight score + L/R wing average. In case if there is only one wing per individual (e.g. left wing avail, while right was damaged or missing), we will keep information from the only available wing.
#we generate an object named AI_NEX by first seperate single/double wing individuals.
df = as.matrix(two.d.array(shapes_aligned$coords))
df = as.data.frame(df)
df$pair = myGPA$pairs
df$size = myGPA$Csize
NEX_wings_sm = df[duplicated(df$pair) | duplicated(df$pair, fromLast=TRUE), ]
NEX_wings_as = df[!df$pair %in% NEX_wings_sm$pair,]
dim(NEX_wings)
dim(NEX_wings_sm)
dim(NEX_wings_as)
NEX_wings_as_average <- aggregate(NEX_wings_sm, by=NEX_wings_sm["pair"], mean )

# One can further check is size differences between right an lest correlate with the flight:
minus <- function(x) {x[1] - x[2]} # I used this to find difference in right versus left
NEX_wings_as_average <- aggregate(NEX_wings_sm$size, by=NEX_wings_sm["pair"], minus )
dim(Nex_wings_AV)

# this needs to be assigned separately because main obejcts has a different order individuals.
Nex_wings_AV$condition = stringr::str_extract(Nex_wings_AV$pair, "^.{7}")
Nex_wings_AV$logsize=  log10(Nex_wings_AV$size)
Nex_wings_AV$condition =  ifelse(Nex_wings_AV$condition == "ctrl_ns", paste("Control diet + no selection"), Nex_wings_AV$condition )
Nex_wings_AV$condition =  ifelse(Nex_wings_AV$condition == "ctrl_fs", paste("Control diet + flight selection"), Nex_wings_AV$condition )
Nex_wings_AV$condition =  ifelse(Nex_wings_AV$condition == "hgSg_ns", paste("High Sugar diet + no selection"), Nex_wings_AV$condition )
Nex_wings_AV$condition =  ifelse(Nex_wings_AV$condition == "hgSg_fs", paste("High Sugar diet + flight selection"), Nex_wings_AV$condition )
ggbetweenstats(
  data  = Nex_wings_AV,
  x     = condition,
  y     = logsize,
  title = "Wing size distribution per group", pairwise.display = "significant", centrality.plotting = F, p.adjust.method = "bonferroni",xlab = "Groups",results.subtitle = FALSE, ylab = "Log 10 -Wing Centrod Size", palette = "Accent")


# 7.3 - Once we checked if the shape of avareage wing per individual correlated with flight, we need to further test if symetry also correlates with flight. To go ahead, we first subset data that always have two wings per individual
AI_NEX$pair =str_split_i(rownames(AI_NEX), "ind",2)
AI_NEX$ai = AI_NEX$`bs$signed.AI`
dim(AI_NEX)
#next we nerge AI_NEX with flight data (complete_integr)
AI_NEX_merges = merge(complete_integr, AI_NEX, by.y  = "pair",) #here we use ids to merge
dim(complete_integr)
dim(AI_NEX_merges)
AI_NEX_merges_na = na.omit(AI_NEX_merges)
ggscatter(AI_NEX_merges_na, x = "ai", y = "Y", add = "reg.line", conf.int = TRUE,cor.coef = TRUE, cor.method = "pearson")

#the last correlations I need to have is for the flight scores!
#now I just need to make a GPA object and go with analysis
AI_NEX_merges_na
cord = as.matrix(AI_NEX_merges_na[,11:40])
shape <- arrayspecs(cord, 15, 2)
nex_mph <- geomorph.data.frame(shape = shape, size = AI_NEX_merges_na$size, id =AI_NEX_merges_na$pair, condition = AI_NEX_merges_na$condition,
                               flight = AI_NEX_merges_na$Y)
wing.pca <- gm.prcomp(shape)
wing.pca$condition = AI_NEX_merges_na$condition
wing.pca$flight = nex_mph$flight

shape.space(wing.pca, group = wing.pca$flight, color = wes_palette("BottleRocket1", type = "continuous"),
            group.title = 'Condition', convex.hulls = F,
            backtransform.examples = TRUE,
            ref.shape = mshape(shape_fx),
            shape.method = "points",
            bt.shape.mag = 4, hull.alpha = 0.1,ref.pt.size = 0.5, target.pt.size = 0.5, lm.labels = F,
            bt.links = fw.links,pt.size = 1, label.groups = F)


```


```{r 8 -> Crossveinless vs flight}
#step 1 - import files with the annotation of cross veins (IDs) per each folder.
#overlap with flight and morphometrics data.
#enrichment analysis for selection/no selection zones.

#Side note: this analysis becomes important only in the context of selection results, can be ignored for now.

#step 2 - check if crossveinless mark (landmark 10) has a strong impact on overall shape of PCA, and variance in wings. Each folder has two set of annotations - flies with two/one missing crossvein.
G0_ID_annotated_crossveinless <-read_csv("~/Desktop/GitHub/2023_Experimental_Evolution_For_Robustness/code/G0_ID_annotated_crossveinless.csv")
G0_ID_annotated_crossveinless = toupper(G0_ID_annotated_crossveinless)
# I need to convert this to some sort of list to ovelap image IDS.
as.data.frame(G0_ID_annotated_crossveinless$Crossveinless_one_wing)

```


```{r 9 -> Object integration heatmap, include=FALSE}

#9.1 This plot should show integration of all traits in a form of a heatmap.
#Basic idea - produce a 'robustness score' for each trait, then visualize this numberic score on a heatmap 
#where each row is a trait and each column is an individual (1200 inds). This design would help to show 
#how robustness might be similar/different across traits. Robustness score can be defined as MAD (Median Absolute Deviation) for non-parametric traits (flight, symmetry) and as AAD (Average Absolute Deviation) for parametric traits such as wing shape and size.

# step 1 - small dummy dataset with 1 replica. This format contains everything needed (landmarks, size, flight, etc). Need to be adjusted first.
dummy_heatmap <- readRDS("~/Desktop/GitHub/2023_Experimental_Evolution_For_Robustness/code/dummy.RDS")

#To plot AAD of wing shape, I need to figure out the mean first. mshape function can be quite handy, but the output of the substraction will still be a multivariate vector. How do I visualize variation around the mean in a univariate way?
    - #1 Approach can be to compute AAD score from PC1 that captures most (but not all variation)
    - #2 Approach two Procrustes distance from mshape and each individual? This can be achieved with ShapeDist function from evomorph, yay.
wing_variation = ShapeDist(shapes = dummy_heatmap[, 11: 40], reference = mshape(arrayspecs(dummy_heatmap[, 11: 40], 15, 2)))
#To plot MAD of wing size, there is a function in base R called mad(). However mad returns only one value in contrast to what I am trying to achieve. This value is a median of all differences, I need each value plotted, thus this function should suffice instead:
size_robustness = abs(dummy_heatmap$size - median(dummy_heatmap$size))
#flight MAD
flight_robustness = abs(dummy_heatmap$Y - median(dummy_heatmap$Y)) #One problem of this approach above is that we need to normalize mad scores for each replica?
ai_robustness = abs(dummy_heatmap$ai - median(dummy_heatmap$ai))
#size asymmetry should also be added to the heatmap. Something interesting here is that size also has both 
#directional and fluctuating component. I assume that average size of L - R does not equal to 0. Would be great to 
#note that value somewhere for a reference.
#I need to perform LRsize_difference calculation earlier to have this variable on hand.
hist(size_asymmetry_robustness$LRsize_difference)
#check histogram of LRsize_difference beforehand to decide weather median or mean is used.
size_asymmetry_robustness = abs(dummy_heatmap$LRsize_difference - median(dummy_heatmap$LRsize_difference))

#Here should be step to scale values
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
ai_robustness = range01(ai_robustness)
size_robustness = range01(size_robustness)
flight_robustness = range01(flight_robustness)
wing_variation = range01(wing_variation)
size_asymmetry_robustness = range01(size_asymmetry_robustness)


robustness_heatmap = rbind(wing_variation,size_robustness,flight_robustness,ai_robustness, size_asymmetry_robustness) #this dataframe contains between 1000 - 1200 values for all traits.

#Different traits have different Mean/Median values those I need to scale them to plot each trait on a scale between 0 and 1. In this case 0 is closest to either mean or median and 1 is the furthest away (least robust).
#robustness_heatmap = scale(robustness_heatmap)
pheatmap(robustness_heatmap, cluster_rows = FALSE,
         cluster_cols = T,
         show_rownames=T,
         show_colnames = T, )
         #annotation_col=classifier)
#Pretty good, but normalisation on replica-level should still exist.


#Colomns of the heatmap should seperate two conditions for clarity. Those classifier is diet.
#One last thing that can be added into this heatmap is corssveinless classifier.
#classifier = as.data.frame(dummy_heatmap$condition,dummy_heatmap$pair)

#Point for future: those robustness scores need to be normalized between different assays/replicas differently? Or perhaps a universal median/mean value could be used to describe a population under its treatment. Here I just need to be sure that certain replicas are not displayed differently in robustness just because their mean on average is lower/higher if that makes sence.
# this normalisation would look different for different traits. In case of asymetry by default mean differences are removed by the package, thus should be good.
#Normalisation for wing AAD.
#Normalisation for flight MAD?



# 9.2 - Deviation from the mean/median can be both positive and negative. In some casees, heatmap can be done for those values without taking an absolute value because positive deviation for two traits may correlate. However, in this case this won't be a classic mad/aad analysis. Here I will calculate something similar to mad/aad except that the difference will be signed
#All values below would produce postive/negative values, except for AI values because bilat.symmetry produces only positive values. 
#Actually ShapeDist also produces only positive values as the distance from the mean can't be negative. The values are square root of the sum of squared differences in the posititions of the landmarks in two shapes. Square root of squared differences are by default positive. 
#So only size and flight can have signed values for deviation from the mean. Symmetry values can hypothetically be produces but I need to implement one of the Palmer's formulas by hand instead of using geomorph.

size_robustness = dummy_heatmap$size - median(dummy_heatmap$size)
flight_robustness = dummy_heatmap$Y - median(dummy_heatmap$Y)
ai_robustness = dummy_heatmap$ai - median(dummy_heatmap$ai) #This doesn't produce signed values.

# Next each trait should be scaled between -1 and 1.

#9.3 - PCA plot made with robustness scores

#copying this from the older code, just change variable names/condition where needed
#cct = assay(robustness_heatmap, blind  = T)
PCA <- prcomp(t(robustness_heatmap), scale = F)
percentVar <- round(100 * PCA$sdev ^ 2/ sum(PCA$sdev ^ 2), 1)
plotPCA.df = data.frame(PC1 = PCA$x[,1], PC2 = PCA$x[,2], PC3 = PCA$x[,3], PC4 = PCA$x[,4])
                       # sample = paste0(colData(dds)$SampleID,"_", colData(dds)$age),  #change meta data here
                       # condition = as.character(colData(dds)$age), batch = colData(dds)$mutation) #there is a chance to make corrections for batch or assays here

qplot(PC1, PC2, data = plotPCA.df, #color = as.factor(dds$Condition), main = "PC1 vs PC2 of robustness scores",
      size = I(6))+ labs(x = paste0("PC1, VarExp:", round(percentVar[1],4)),  y = paste0("PC2, VarExp:", round(percentVar[2],4))) + scale_color_manual(values = colorRampPalette(brewer.pal(n = 5, name = "RdBu"))(4))+ theme_classic() + theme(aspect.ratio=1)

#done, add colors:)

```

```{r 10 -> Variability in egg-lay pattern, include=TRUE}
#This is supplementary part of Go, that was completed seperately by exposing NEX to HS for 1 generation and estimating variability of fecundity in two conditions

#25.12.24, Saudat Alishayeva
#Analysis of fecundity/develpoment/egg-to-adult survival in NEX population (exposed to HS vs Control)

#Input format: data include 5 egg-lays and 10 replicas. Each egg-lay lead to several collections of adults (2-3).
#collections are only important in reference to the developmental timing, therefore can be safely ignored for some analysis after merging the data.

#Question 1: Do flies exhibit more variable egg-laying behavior in high-sugar compared to control groups?
#To answer this question, I will check for variation in number of eggs across replicas and time-points. 
#I will first look at overall result and then visualize variaiton across time-points seperately since some variation can be noted on the later stages due to artifacts (e.g. flies died in a few vials).

#Import fecundity data
setwd("~/Desktop/code/fecundity_NEX/")
fecundity <- read.delim("NEX_fecundity_expanded_E4_E6.txt")
fecundity$ID = paste(fecundity$Group,fecundity$Vial, sep = "_")

#libraries


#plot the data, but to plot everything I need to reshape it first
#here column time now saves information about each egg-lay in integer form, we need to convert it to a character or a factor
fecundity_reshaped = reshape(fecundity, idvar = "ID", varying = list(3:8), direction = "long")
fecundity_reshaped$time = as.factor(fecundity_reshaped$time)
#now a violin or histogram should be enough to see the variance 
ggplot(fecundity_reshaped, aes(x=Group, y=E1, fill=Group)) + geom_violin(trim=FALSE) + theme_minimal() + geom_dotplot(binaxis='y', stackdir='center', position=position_dodge(1)) + ylab("Variation in fecundity across replicas/time points")
#dotplot to understand if there're any biases coming from replicas not group as the whole.
ggplot(fecundity_reshaped, aes(x=ID, y=E1, fill=ID)) + theme_minimal() + geom_dotplot(binaxis='y', stackdir='center', position=position_dodge(1), dotsize = 0.6) + ylab("Variation in fecundity across replicas/time points")
#now ploting the same thing but for egg-lays
ggplot(fecundity_reshaped, aes(x=time, y=E1, fill=Group)) + theme_minimal() + geom_dotplot(binaxis='y', stackdir='center', position=position_dodge(1), dotsize = 0.6) + ylab("Variation in fecundity across replicas/time points")

#statistical tests for variability
# Question: does high-sugar cause more variable egg-laying behavior compared to control?
# There are three ways to answer this:
# 1. Test for variance group 1 vs group 2
bf.test(E1 ~ Group, data = fecundity_reshaped[fecundity_reshaped$ID != "NEX_HS_7",])
kruskal.test(E1 ~ Group, data = fecundity_reshaped) 

#Results:   Brown-Forsythe Test -> significant ... Kruskal-Wallis -> not-significant
#If I remove vial #7 then the result becomes non-significant, but its okay otherwise
# 2. Get a measure of variability for each vial (across 6 collections) and compare sd scores between groups (10 vs 10 values)
# 2.1 - first lets make a plot ouf of this. We can use IQR,sd,mad as a stats summary 

#based on these two plots, I can identify potential outlier vials

ggplot(fecundity_reshaped, aes(x=as.factor(fecundity_reshaped$Vial), y=E1)) + labs(title = "Variability" ) + theme(axis.text.x = element_text(size = 8))+ xlab("Egg-lay") + ylab("Variability")+ stat_summary(fun = "sd",aes(color=paste(Group))) + theme_minimal() +scale_fill_viridis(discrete = T)

ggplot(fecundity_reshaped, aes(x=Group, y=E1)) + labs(title = "Variability" ) + theme(axis.text.x = element_text(size = 8))+ xlab("Egg-lay") + ylab("Variability")+ stat_summary(fun = "IQR",aes(color=paste(as.factor(fecundity_reshaped$Vial)))) + theme_minimal() +scale_fill_viridis(discrete = T)

#We can first try using the Brown–Forsythe test. This test is similar to Levene test in a sence that it calculates  deviation from the median, except it doesn't require distributions to be parametric. 

bf.test(E1 ~ Group, data = fecundity_reshaped[fecundity_reshaped$Vial == 3,])
kruskal.test(E1 ~ Group, data = fecundity_reshaped[fecundity_reshaped$Vial == 7,]) 
#Vials 3 and 7 contribute in a stat sign way

# 3. Compare if variability peaks across different time-points in 10 replicas (6 vs 6 values).
ggplot(fecundity_reshaped, aes(x=as.factor(fecundity_reshaped$time), y=E1, fill = Group)) + labs(title = "Variability" ) + theme(axis.text.x = element_text(size = 8))+ xlab("Egg-lay") + ylab("Variability")+ stat_summary(fun = "IQR",aes(color=paste(Group))) + theme_minimal() +scale_fill_viridis(discrete = T)
#Yes it seems that the most pronounced difference in fecundity variability starts at E3, which corresponds to fruit fly age of ~8 days old.

bf.test(E1 ~ Group, data = fecundity_reshaped[fecundity_reshaped$time == 2,]) #only time point 2 is significant
kruskal.test(E1 ~ Group, data = fecundity_reshaped[fecundity_reshaped$time == 2,])  #only time point 2 is significant
```




```{r 11 -> Object summary, include=FALSE}
''' Quick summary of ojects produced throughtout analysis. Internal directory, mostly for organizing purposes:

    -> 1. Read files: stucture G0RX
    -> 2. File imported to Morphoj for checks on swapped landmarks: complete.Rmd -> "NEX_morphometrics_Go.txt" -> NEX_wings.Rmd
    -> 3. Geomorph ojects: myGPA [generic PCA], bs [bilaterial symetry viz], bs_control and bs_hs [DA/FA seperated by condition]
    -> 4. Integration with flight data: complete_integr [step 1], 
                                        AI_NEX [step 2 - flight vs symetry -> subset of flies with 2 wings]
                                        NEX_wings_as_average [step 3 - flight vs wing size -> average size wings]
                                        Nex_wings_AV [step 4 - flight vs wing shape -> average wings]
                                        NEX_crossveinless [integration of flight and corssveinless phenotypes]
                                        #I concatenated all flight csv files, preserving rownames and order
                                        Go_females_0523_flight_complete
                                        #I also concatinated each order_id into file where each colomn is a 
                                        Go_female_0523_orderID_complete
                                        #wing data can be named as
                                        Go_female_0523_wings_complete
                                        G0_ID_annotated_crossveinless - crossveinless file


```


